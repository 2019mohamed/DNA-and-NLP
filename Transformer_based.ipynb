{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer based.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPti7HJL/2xsv3ZygzDh2aM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2019mohamed/DNA-and-NLP/blob/main/Transformer_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFJAZmU8T12g",
        "outputId": "70ba66aa-6cbf-4501-934f-d00338950ecd"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler , BatchSampler\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class SeqData (Dataset):\n",
        "    def __init__(self):\n",
        "        data = pd.read_csv('promoters.csv')\n",
        "        data['Sequence'] = data['Sequence'].str.replace('\\t\\t' , '')\n",
        "        data['Sequence'] = data['Sequence'].str.replace('\\t' , '')\n",
        "        self.seqs = list(data['Sequence'])\n",
        "        #print(self.seqs[0])\n",
        "        self.maxlen = len(max(self.seqs , key = lambda k :len(k)))\n",
        "        self.labels = list(data['Class'])\n",
        "        self.map = {'a':0 , 'c':1 , 'g':2 , 't':3 }\n",
        "        #print(self.seqs[34],' ',self.labels[34])\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = np.zeros((self.maxlen,len(self.map)))\n",
        "        seq = self.seqs[index].lower()\n",
        "        for i, alpa in enumerate(seq):\n",
        "            x[i,self.map[alpa]] = 1\n",
        "        #print(x)\n",
        "        l = 0 if self.labels[index] == '+' else 1\n",
        "        return x , l\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler , BatchSampler\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"MLP with linear output\"\"\"\n",
        "    def __init__(self, num_layers, input_dim, hidden_dim, output_dim):\n",
        "        \"\"\"MLP layers construction\n",
        "        Paramters\n",
        "        ---------\n",
        "        num_layers: int\n",
        "            The number of linear layers\n",
        "        input_dim: int\n",
        "            The dimensionality of input features\n",
        "        hidden_dim: int\n",
        "            The dimensionality of hidden units at ALL layers\n",
        "        output_dim: int\n",
        "            The number of classes for prediction\n",
        "        \"\"\"\n",
        "        super(MLP, self).__init__()\n",
        "        self.linear_or_not = True  # default is linear model\n",
        "        self.num_layers = num_layers\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        if num_layers < 1:\n",
        "            raise ValueError(\"number of layers should be positive!\")\n",
        "        elif num_layers == 1:\n",
        "            # Linear model\n",
        "            self.linear = nn.Linear(input_dim, output_dim)\n",
        "        else:\n",
        "            # Multi-layer model\n",
        "            self.linear_or_not = False\n",
        "            self.linears = torch.nn.ModuleList()\n",
        "            self.batch_norms = torch.nn.ModuleList()\n",
        "\n",
        "            self.linears.append(nn.Linear(input_dim, hidden_dim))\n",
        "            for layer in range(num_layers - 2):\n",
        "                self.linears.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            self.linears.append(nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "            for layer in range(num_layers - 1):\n",
        "                self.batch_norms.append(nn.BatchNorm1d((hidden_dim)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.linear_or_not:\n",
        "            # If linear model\n",
        "            return self.linear(x)\n",
        "        else:\n",
        "            # If MLP\n",
        "            h = x\n",
        "            for i in range(self.num_layers - 1):\n",
        "                h = F.relu(self.linears[i](h))\n",
        "            return self.linears[-1](h)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, len_sequence, segment_size, embedding_size, hidden_size, trans_layers, readout_layers, alphabet_size=4,\n",
        "                 dropout=0.0, heads=1, layer_norm=False, mask='empty'):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.segment_size = segment_size\n",
        "\n",
        "        if mask == \"empty\":\n",
        "            self.mask_sequence = generate_empty_mask(len_sequence//segment_size)\n",
        "        elif mask == \"no_prev\":\n",
        "            self.mask_sequence = generate_square_previous_mask(len_sequence//segment_size)\n",
        "        elif mask[:5] == \"local\":\n",
        "            self.mask_sequence = generate_local_mask(len_sequence//segment_size, k=int(mask[5:]))\n",
        "\n",
        "        self.sequence_trans = TransformerEncoderModel(ntoken=alphabet_size*segment_size, nout=hidden_size, ninp=hidden_size,\n",
        "                                                  nhead=heads, nhid=hidden_size, nlayers=trans_layers, dropout=dropout,\n",
        "                                                  layer_norm=layer_norm, max_len=len_sequence//segment_size)\n",
        "\n",
        "        self.readout = MLP(input_dim=len_sequence // segment_size * hidden_size, hidden_dim=embedding_size, output_dim=embedding_size, num_layers=readout_layers)\n",
        "                           \n",
        "\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        # sequence (B, N, 4)\n",
        "        (B, N, _) = sequence.shape\n",
        "\n",
        "        # apply attention layers\n",
        "        sequence = sequence.reshape((B, N//self.segment_size, -1)).transpose(0, 1)\n",
        "        enc_sequence = self.sequence_trans(sequence, self.mask_sequence)\n",
        "\n",
        "        # apply readout\n",
        "        enc_sequence = enc_sequence.transpose(0, 1).reshape(B, -1)\n",
        "        embedding = self.readout(enc_sequence)\n",
        "        return embedding\n",
        "\n",
        "\n",
        "class TransformerEncoderModel(nn.Module):\n",
        "    \"\"\" Part of this code was adapted from the examples of the PyTorch library \"\"\"\n",
        "\n",
        "    def __init__(self, ntoken, nout, ninp, nhead, nhid, nlayers, max_len, dropout=0.0, layer_norm=False):\n",
        "        super(TransformerEncoderModel, self).__init__()\n",
        "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout, max_len=max_len)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers, norm= \\\n",
        "            nn.LayerNorm(normalized_shape=ninp, eps=1e-6) if layer_norm else None)\n",
        "        self.encoder = nn.Linear(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, nout)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=10000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "def generate_square_previous_mask(sz):\n",
        "    mask = (torch.triu(torch.ones(sz, sz)) == 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def generate_local_mask(sz, k=3):\n",
        "    mask = torch.eye(sz)\n",
        "    for i in range(1, k + 1):\n",
        "        mask += torch.cat((torch.zeros(i, sz), torch.eye(sz)[:-i]), dim=0)\n",
        "        mask += torch.cat((torch.zeros(sz, i), torch.eye(sz)[:, :-i]), dim=1)\n",
        "\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def generate_empty_mask(sz):\n",
        "    mask = torch.zeros(sz, sz)\n",
        "    return mask\n",
        "\n",
        "def split_rand(dataset,batch_size, split_ratio=0.7, seed=42, shuffle=True):\n",
        "    import math\n",
        "    num_entries = len(dataset)\n",
        "    indices = list(range(num_entries))\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(math.floor(split_ratio * num_entries))\n",
        "    train_idx, valid_idx = indices[:split], indices[split:]\n",
        "    \n",
        "    \n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "            dataset, sampler=train_sampler,\n",
        "            batch_size=batch_size)\n",
        "    \n",
        "    valid_loader = DataLoader(\n",
        "            dataset, sampler=valid_sampler,\n",
        "            batch_size=batch_size)\n",
        "\n",
        "    return train_loader, valid_loader\n",
        "\n",
        "def train(net, trainloader, optimizer, criterion):\n",
        "    net.train()\n",
        "\n",
        "    running_loss = 0\n",
        "    total_iters = len(trainloader)\n",
        "\n",
        "    for idx , data  in enumerate(trainloader):\n",
        "\n",
        "        x, labels = data\n",
        "        outputs = net(x.float())\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    running_loss = running_loss / total_iters\n",
        "\n",
        "    return running_loss\n",
        "\n",
        "def eval_net(net, dataloader, criterion):\n",
        "    net.eval()\n",
        "\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    for idx ,  data in enumerate(dataloader):\n",
        "        x, labels = data\n",
        "\n",
        "        total += len(labels)\n",
        "        outputs = net(x.float())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total_correct += (predicted == labels.data).sum().item()\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item() * len(labels)\n",
        "\n",
        "    loss, acc = 1.0*total_loss / total, 1.0*total_correct / total\n",
        "\n",
        "\n",
        "    return loss, acc\n",
        "\n",
        "\n",
        "\n",
        "dataset = SeqData()\n",
        "\n",
        "model = Transformer (readout_layers = 2, hidden_size = 64 , trans_layers = 2 , segment_size = 57,  heads = 8 ,  layer_norm=False , embedding_size=128,\n",
        "                    len_sequence = 57 )\n",
        "\n",
        "train_loader , test_loader = split_rand(dataset, batch_size = 16)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for _ in range(500):\n",
        "    print(train(model, train_loader, optimizer, criterion))\n",
        "    \n",
        "    print(eval_net(model, test_loader, criterion))\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.621615314483643\n",
            "(4.074456691741943, 0.65625)\n",
            "3.585037851333618\n",
            "(2.8197051286697388, 0.46875)\n",
            "2.124591088294983\n",
            "(1.2110081315040588, 0.46875)\n",
            "0.8958014845848083\n",
            "(0.7132685482501984, 0.40625)\n",
            "0.6626940488815307\n",
            "(0.6979579627513885, 0.40625)\n",
            "0.6314382553100586\n",
            "(0.6404063701629639, 0.75)\n",
            "0.5582497477531433\n",
            "(0.5475876033306122, 0.9375)\n",
            "0.3720456659793854\n",
            "(0.345610573887825, 0.875)\n",
            "0.13121481984853745\n",
            "(0.21237029135227203, 0.9375)\n",
            "0.04211123213171959\n",
            "(0.24333789199590683, 0.90625)\n",
            "0.01967153958976269\n",
            "(0.25595518201589584, 0.9375)\n",
            "0.00611236309632659\n",
            "(0.26373300701379776, 0.9375)\n",
            "0.0023978045675903557\n",
            "(0.27077573991846293, 0.9375)\n",
            "0.001294133672490716\n",
            "(0.2759672701358795, 0.9375)\n",
            "0.0008651306503452361\n",
            "(0.2787700966000557, 0.9375)\n",
            "0.0006644129520282149\n",
            "(0.2804830027744174, 0.9375)\n",
            "0.0005550084519200027\n",
            "(0.2815995393320918, 0.9375)\n",
            "0.00048698969767428933\n",
            "(0.2825254537165165, 0.9375)\n",
            "0.0004422612255439162\n",
            "(0.2830926850438118, 0.9375)\n",
            "0.0004125510982703418\n",
            "(0.28345635777805, 0.9375)\n",
            "0.00038596679805777965\n",
            "(0.28396121645346284, 0.9375)\n",
            "0.00036748277489095926\n",
            "(0.2843832350336015, 0.9375)\n",
            "0.0003477833641227335\n",
            "(0.28475384786725044, 0.9375)\n",
            "0.000333238992607221\n",
            "(0.28519380232319236, 0.9375)\n",
            "0.00031967360409908\n",
            "(0.2856789156794548, 0.9375)\n",
            "0.0003037150134332478\n",
            "(0.28621190786361694, 0.9375)\n",
            "0.00029218950658105314\n",
            "(0.28647060692310333, 0.9375)\n",
            "0.000282006966881454\n",
            "(0.2868014276464237, 0.9375)\n",
            "0.0002681655139895156\n",
            "(0.28724061138927937, 0.9375)\n",
            "0.00025879762833938005\n",
            "(0.28770796582102776, 0.9375)\n",
            "0.00024967038771137593\n",
            "(0.2881011026329361, 0.9375)\n",
            "0.00024234237207565457\n",
            "(0.2884879447519779, 0.9375)\n",
            "0.00023105472791939974\n",
            "(0.28897663578391075, 0.9375)\n",
            "0.00022351561638060956\n",
            "(0.2894579122075811, 0.9375)\n",
            "0.00021398842218331993\n",
            "(0.2900132089853287, 0.9375)\n",
            "0.00020734130230266602\n",
            "(0.2906038109213114, 0.9375)\n",
            "0.00019978560449089854\n",
            "(0.2910375203937292, 0.9375)\n",
            "0.0001926097582327202\n",
            "(0.2915856074541807, 0.9375)\n",
            "0.00018413766520097852\n",
            "(0.29212773754261434, 0.9375)\n",
            "0.00017762854404281824\n",
            "(0.2927355665160576, 0.9375)\n",
            "0.00017167813202831895\n",
            "(0.2932655978947878, 0.9375)\n",
            "0.00016486975364387034\n",
            "(0.29388772282982245, 0.9375)\n",
            "0.00016004350618459284\n",
            "(0.29444198310375214, 0.9375)\n",
            "0.00015455480315722524\n",
            "(0.29503959412977565, 0.9375)\n",
            "0.0001499260513810441\n",
            "(0.2955698687583208, 0.9375)\n",
            "0.0001424956280970946\n",
            "(0.2962309308350086, 0.9375)\n",
            "0.0001391433906974271\n",
            "(0.29684152640402317, 0.9375)\n",
            "0.00013411672989604995\n",
            "(0.297450888203457, 0.9375)\n",
            "0.00013139442016836257\n",
            "(0.29799056029878557, 0.9375)\n",
            "0.00012763712875312193\n",
            "(0.2986344040837139, 0.9375)\n",
            "0.00012299424270167947\n",
            "(0.2993261836381862, 0.9375)\n",
            "0.00011933171044802293\n",
            "(0.300012001520372, 0.9375)\n",
            "0.00011427366698626428\n",
            "(0.300690783187747, 0.9375)\n",
            "0.00011227568029426038\n",
            "(0.30137076834216714, 0.9375)\n",
            "0.00010826475481735542\n",
            "(0.30206460275076097, 0.9375)\n",
            "0.0001050089209456928\n",
            "(0.30275089479982853, 0.9375)\n",
            "0.00010316765983588993\n",
            "(0.30343539209570736, 0.9375)\n",
            "9.993356798077002e-05\n",
            "(0.30411764793097973, 0.9375)\n",
            "9.695662010926754e-05\n",
            "(0.304801009617222, 0.9375)\n",
            "9.364412690047175e-05\n",
            "(0.30550491996109486, 0.9375)\n",
            "9.194379526888952e-05\n",
            "(0.30618718691403046, 0.9375)\n",
            "8.885657734936103e-05\n",
            "(0.3068838566541672, 0.9375)\n",
            "8.65712485392578e-05\n",
            "(0.30761195335071534, 0.9375)\n",
            "8.427490101894363e-05\n",
            "(0.30832770257256925, 0.9375)\n",
            "8.124963787849992e-05\n",
            "(0.309082405641675, 0.9375)\n",
            "8.016612846404315e-05\n",
            "(0.3097921152366325, 0.9375)\n",
            "7.725825707893819e-05\n",
            "(0.31055638409452513, 0.9375)\n",
            "7.61607414460741e-05\n",
            "(0.3112965542823076, 0.9375)\n",
            "7.342748285736889e-05\n",
            "(0.3120402321219444, 0.9375)\n",
            "7.165945862652734e-05\n",
            "(0.3127646744251251, 0.9375)\n",
            "6.921495223650709e-05\n",
            "(0.313489630818367, 0.9375)\n",
            "6.8346293119248e-05\n",
            "(0.31422668835148215, 0.9375)\n",
            "6.591400160687045e-05\n",
            "(0.3149215573212132, 0.9375)\n",
            "6.542588380398229e-05\n",
            "(0.3156249448657036, 0.9375)\n",
            "6.302130204858259e-05\n",
            "(0.31635008938610554, 0.9375)\n",
            "6.232755840756e-05\n",
            "(0.3170505129965022, 0.9375)\n",
            "6.071804455132224e-05\n",
            "(0.3177707903087139, 0.9375)\n",
            "5.933888896834105e-05\n",
            "(0.31849010279984213, 0.9375)\n",
            "5.794154421892017e-05\n",
            "(0.3192089598160237, 0.9375)\n",
            "5.650576204061508e-05\n",
            "(0.3199257416417822, 0.9375)\n",
            "5.410860248957761e-05\n",
            "(0.32063153013587, 0.9375)\n",
            "5.3851131815463306e-05\n",
            "(0.3213366698473692, 0.9375)\n",
            "5.242725746938959e-05\n",
            "(0.3220240119844675, 0.9375)\n",
            "5.174215039005503e-05\n",
            "(0.3227076381444931, 0.9375)\n",
            "4.988229120499455e-05\n",
            "(0.32340678945183754, 0.9375)\n",
            "4.994726114091463e-05\n",
            "(0.32406190503388643, 0.9375)\n",
            "4.843696151510812e-05\n",
            "(0.3247603327035904, 0.9375)\n",
            "4.7247313341358675e-05\n",
            "(0.3254696290823631, 0.9375)\n",
            "4.554270199150778e-05\n",
            "(0.32616037130355835, 0.9375)\n",
            "4.536301494226791e-05\n",
            "(0.32682812586426735, 0.9375)\n",
            "4.4684450404020024e-05\n",
            "(0.3274769637500867, 0.9375)\n",
            "4.3587480467977004e-05\n",
            "(0.32814427837729454, 0.9375)\n",
            "4.285557515686378e-05\n",
            "(0.3288345318287611, 0.9375)\n",
            "4.2082241998286916e-05\n",
            "(0.3295268364599906, 0.9375)\n",
            "4.058533886563964e-05\n",
            "(0.33023762598168105, 0.9375)\n",
            "4.0376737160841e-05\n",
            "(0.33090890012681484, 0.9375)\n",
            "3.904074983438477e-05\n",
            "(0.33158901071874425, 0.9375)\n",
            "3.910781306331046e-05\n",
            "(0.3322587073780596, 0.9375)\n",
            "3.821497448370792e-05\n",
            "(0.33292592875659466, 0.9375)\n",
            "3.7583486118819565e-05\n",
            "(0.3336190078407526, 0.9375)\n",
            "3.6249886761652306e-05\n",
            "(0.33431885903701186, 0.9375)\n",
            "3.622307085606735e-05\n",
            "(0.33499977365136147, 0.9375)\n",
            "3.458638784650248e-05\n",
            "(0.33569757360965014, 0.9375)\n",
            "3.442546440055594e-05\n",
            "(0.33636296645272523, 0.9375)\n",
            "3.382229042472318e-05\n",
            "(0.33700969628989697, 0.9375)\n",
            "3.320898176752962e-05\n",
            "(0.3376745537825627, 0.9375)\n",
            "3.2120937248691916e-05\n",
            "(0.3383260630071163, 0.9375)\n",
            "3.207236550224479e-05\n",
            "(0.33895527943968773, 0.9375)\n",
            "3.0962562595959754e-05\n",
            "(0.33960798755288124, 0.9375)\n",
            "3.063772965106182e-05\n",
            "(0.34024986159056425, 0.9375)\n",
            "3.0151075407047756e-05\n",
            "(0.340882740167217, 0.9375)\n",
            "2.9642963636433705e-05\n",
            "(0.34147920459508896, 0.9375)\n",
            "2.9319621899048797e-05\n",
            "(0.34209606796503067, 0.9375)\n",
            "2.889227071136702e-05\n",
            "(0.34272298589348793, 0.9375)\n",
            "2.822024871420581e-05\n",
            "(0.3433625139296055, 0.9375)\n",
            "2.7746110572479665e-05\n",
            "(0.3439950570464134, 0.9375)\n",
            "2.7334850892657413e-05\n",
            "(0.34462433867156506, 0.9375)\n",
            "2.666461623448413e-05\n",
            "(0.34526307333726436, 0.9375)\n",
            "2.6602633442962543e-05\n",
            "(0.3458703364885878, 0.9375)\n",
            "2.5974716118071227e-05\n",
            "(0.3465009331703186, 0.9375)\n",
            "2.562842309998814e-05\n",
            "(0.34712951607070863, 0.9375)\n",
            "2.509080295567401e-05\n",
            "(0.34775974974036217, 0.9375)\n",
            "2.4632755958009513e-05\n",
            "(0.34838749654591084, 0.9375)\n",
            "2.440298667352181e-05\n",
            "(0.34897961316164583, 0.9375)\n",
            "2.3741392578813247e-05\n",
            "(0.3495886977761984, 0.9375)\n",
            "2.3758381576044486e-05\n",
            "(0.3501618050504476, 0.9375)\n",
            "2.3125695952330717e-05\n",
            "(0.35076358541846275, 0.9375)\n",
            "2.3198113922262564e-05\n",
            "(0.3513767105760053, 0.9375)\n",
            "2.237499393231701e-05\n",
            "(0.3520061803938006, 0.9375)\n",
            "2.1975354320602493e-05\n",
            "(0.3526213285513222, 0.9375)\n",
            "2.1906811889493837e-05\n",
            "(0.353227878222242, 0.9375)\n",
            "2.1161770200706086e-05\n",
            "(0.35384392757259775, 0.9375)\n",
            "2.1092334282002412e-05\n",
            "(0.3544309608041658, 0.9375)\n",
            "2.069239599222783e-05\n",
            "(0.3550339204084594, 0.9375)\n",
            "2.0696272622444666e-05\n",
            "(0.3556299190968275, 0.9375)\n",
            "2.023136585194152e-05\n",
            "(0.35623208060860634, 0.9375)\n",
            "1.9944376253988595e-05\n",
            "(0.35681481671053916, 0.9375)\n",
            "1.9714009249582885e-05\n",
            "(0.35740967094898224, 0.9375)\n",
            "1.8979099513671828e-05\n",
            "(0.3580037027131766, 0.9375)\n",
            "1.907416844915133e-05\n",
            "(0.3585781608708203, 0.9375)\n",
            "1.849184263846837e-05\n",
            "(0.3591619480866939, 0.9375)\n",
            "1.8296046619070694e-05\n",
            "(0.3597182184457779, 0.9375)\n",
            "1.8376213483861646e-05\n",
            "(0.3602832015603781, 0.9375)\n",
            "1.7924419444170782e-05\n",
            "(0.36087345507985447, 0.9375)\n",
            "1.7767960162018426e-05\n",
            "(0.3614626614289591, 0.9375)\n",
            "1.7498851957498118e-05\n",
            "(0.3620392456650734, 0.9375)\n",
            "1.7388883497915232e-05\n",
            "(0.3626129701733589, 0.9375)\n",
            "1.7070004832930864e-05\n",
            "(0.3632056650239974, 0.9375)\n",
            "1.691831330390414e-05\n",
            "(0.36379883969493676, 0.9375)\n",
            "1.647724784561433e-05\n",
            "(0.3643905319913756, 0.9375)\n",
            "1.6617019537079613e-05\n",
            "(0.36496252939105034, 0.9375)\n",
            "1.62906897458015e-05\n",
            "(0.3655409049242735, 0.9375)\n",
            "1.553938491269946e-05\n",
            "(0.36612918227910995, 0.9375)\n",
            "1.54315026520635e-05\n",
            "(0.3667084061598871, 0.9375)\n",
            "1.5105172860785387e-05\n",
            "(0.3672537875809212, 0.9375)\n",
            "1.5024707863631193e-05\n",
            "(0.3678135387599468, 0.9375)\n",
            "1.5070305926201399e-05\n",
            "(0.36834278143942356, 0.9375)\n",
            "1.4689735871797894e-05\n",
            "(0.368884544383036, 0.9375)\n",
            "1.4607483535655774e-05\n",
            "(0.36940648779273033, 0.9375)\n",
            "1.4371154429682065e-05\n",
            "(0.3699263900052756, 0.9375)\n",
            "1.4336585081764497e-05\n",
            "(0.37046712936717086, 0.9375)\n",
            "1.4233769434213173e-05\n",
            "(0.3710145726799965, 0.9375)\n",
            "1.4067772826820147e-05\n",
            "(0.371560487896204, 0.9375)\n",
            "1.3724157361139077e-05\n",
            "(0.3721131421625614, 0.9375)\n",
            "1.3546836817113217e-05\n",
            "(0.37266548280604184, 0.9375)\n",
            "1.3281301653478294e-05\n",
            "(0.37319906761422317, 0.9375)\n",
            "1.3274745651870034e-05\n",
            "(0.3737362436950207, 0.9375)\n",
            "1.3005336586502381e-05\n",
            "(0.3742828406393528, 0.9375)\n",
            "1.2868247904407325e-05\n",
            "(0.37481284514069557, 0.9375)\n",
            "1.2697483180090785e-05\n",
            "(0.3753350041806698, 0.9375)\n",
            "1.2410191993694753e-05\n",
            "(0.3758739472832531, 0.9375)\n",
            "1.2586024422489572e-05\n",
            "(0.37637731432914734, 0.9375)\n",
            "1.2363106179691385e-05\n",
            "(0.37689516320824623, 0.9375)\n",
            "1.2348802556516603e-05\n",
            "(0.37741154804825783, 0.9375)\n",
            "1.2068664364051074e-05\n",
            "(0.3779436908662319, 0.9375)\n",
            "1.190981984109385e-05\n",
            "(0.37847336376717067, 0.9375)\n",
            "1.184991779155098e-05\n",
            "(0.37899512029252946, 0.9375)\n",
            "1.1801341133832467e-05\n",
            "(0.3795093207154423, 0.9375)\n",
            "1.1199340769962874e-05\n",
            "(0.380061075091362, 0.9375)\n",
            "1.1249706585658713e-05\n",
            "(0.3805729867890477, 0.9375)\n",
            "1.1255667777732014e-05\n",
            "(0.38108869229654374, 0.9375)\n",
            "1.1065829130529892e-05\n",
            "(0.38158565387129784, 0.9375)\n",
            "1.1020231977454386e-05\n",
            "(0.38208935037255287, 0.9375)\n",
            "1.0932018085441086e-05\n",
            "(0.38260537857422605, 0.9375)\n",
            "1.0962119631585665e-05\n",
            "(0.38311694213189185, 0.9375)\n",
            "1.0543102689553052e-05\n",
            "(0.38363858312368393, 0.9375)\n",
            "1.0476345960341859e-05\n",
            "(0.38414008542895317, 0.9375)\n",
            "1.031601150316419e-05\n",
            "(0.3846497870981693, 0.9375)\n",
            "1.018667098833248e-05\n",
            "(0.3851671207230538, 0.9375)\n",
            "1.010173527902225e-05\n",
            "(0.3856770135462284, 0.9375)\n",
            "1.0090709656651597e-05\n",
            "(0.3861878506904759, 0.9375)\n",
            "1.003527722787112e-05\n",
            "(0.38667933267424814, 0.9375)\n",
            "9.728316581458784e-06\n",
            "(0.3871889978181571, 0.9375)\n",
            "9.758416854310781e-06\n",
            "(0.38769520819187164, 0.9375)\n",
            "9.534305536362809e-06\n",
            "(0.38820239529013634, 0.9375)\n",
            "9.57483716774732e-06\n",
            "(0.38869306445121765, 0.9375)\n",
            "9.391256571689156e-06\n",
            "(0.38918883353471756, 0.9375)\n",
            "9.246120862371754e-06\n",
            "(0.38968366384506226, 0.9375)\n",
            "9.167145799438004e-06\n",
            "(0.39016808080486953, 0.9375)\n",
            "9.151350968750194e-06\n",
            "(0.39065928757190704, 0.9375)\n",
            "9.001445869216696e-06\n",
            "(0.39114828998208395, 0.9375)\n",
            "8.973432341008446e-06\n",
            "(0.391628623008728, 0.9375)\n",
            "8.750811866775621e-06\n",
            "(0.3921203473582864, 0.9375)\n",
            "8.822634481475688e-06\n",
            "(0.39258962869644165, 0.9375)\n",
            "8.674517994222697e-06\n",
            "(0.39307661447674036, 0.9375)\n",
            "8.42358522277209e-06\n",
            "(0.3935719182481989, 0.9375)\n",
            "8.443552178505343e-06\n",
            "(0.39404159411787987, 0.9375)\n",
            "8.286495540232863e-06\n",
            "(0.39452383294701576, 0.9375)\n",
            "8.271892693301196e-06\n",
            "(0.39499549472748186, 0.9375)\n",
            "8.127054479700746e-06\n",
            "(0.3954608771164203, 0.9375)\n",
            "8.23493846837664e-06\n",
            "(0.39592135325074196, 0.9375)\n",
            "7.966123393998715e-06\n",
            "(0.39638038724660873, 0.9375)\n",
            "7.928871491458267e-06\n",
            "(0.3968590684235096, 0.9375)\n",
            "7.93274584793835e-06\n",
            "(0.39733113744296134, 0.9375)\n",
            "7.69760699768085e-06\n",
            "(0.3977983449585736, 0.9375)\n",
            "7.575120889669051e-06\n",
            "(0.39826579112559557, 0.9375)\n",
            "7.540550359408371e-06\n",
            "(0.3987198546528816, 0.9375)\n",
            "7.502999596908921e-06\n",
            "(0.39917244389653206, 0.9375)\n",
            "7.415381696773693e-06\n",
            "(0.39962795336032286, 0.9375)\n",
            "7.528034166170982e-06\n",
            "(0.40007556322962046, 0.9375)\n",
            "7.3575658461777495e-06\n",
            "(0.40054503083229065, 0.9375)\n",
            "7.190972155513009e-06\n",
            "(0.4010141007602215, 0.9375)\n",
            "7.0398753450717775e-06\n",
            "(0.4014580547809601, 0.9375)\n",
            "7.094711418176303e-06\n",
            "(0.40189240383915603, 0.9375)\n",
            "6.868513446534053e-06\n",
            "(0.40235287696123123, 0.9375)\n",
            "6.926925743755419e-06\n",
            "(0.40279219672083855, 0.9375)\n",
            "6.9293101660150566e-06\n",
            "(0.4032199529765421, 0.9375)\n",
            "6.843480332463514e-06\n",
            "(0.40367016941308975, 0.9375)\n",
            "6.66645564706414e-06\n",
            "(0.4041236527264118, 0.9375)\n",
            "6.668243713647826e-06\n",
            "(0.40455858781933784, 0.9375)\n",
            "6.619666601181962e-06\n",
            "(0.404993437230587, 0.9375)\n",
            "6.59403685858706e-06\n",
            "(0.405444148927927, 0.9375)\n",
            "6.5302602706651666e-06\n",
            "(0.40589864552021027, 0.9375)\n",
            "6.4122437834157605e-06\n",
            "(0.4063478261232376, 0.9375)\n",
            "6.30823424216942e-06\n",
            "(0.4067803844809532, 0.9375)\n",
            "6.340122581605101e-06\n",
            "(0.4072132471992518, 0.9375)\n",
            "6.303465852397494e-06\n",
            "(0.4076453931629658, 0.9375)\n",
            "6.093062984291464e-06\n",
            "(0.40808322350494564, 0.9375)\n",
            "6.119586942077149e-06\n",
            "(0.4084985665977001, 0.9375)\n",
            "6.092467356211273e-06\n",
            "(0.40892007194270263, 0.9375)\n",
            "6.0552146351255946e-06\n",
            "(0.40934647247195244, 0.9375)\n",
            "6.040015614416916e-06\n",
            "(0.40977023599043605, 0.9375)\n",
            "5.997398784529651e-06\n",
            "(0.41019389405846596, 0.9375)\n",
            "5.998293181619374e-06\n",
            "(0.4106349088251591, 0.9375)\n",
            "5.779843195341527e-06\n",
            "(0.41107149701565504, 0.9375)\n",
            "5.800108374387491e-06\n",
            "(0.4114997982978821, 0.9375)\n",
            "5.766730100731365e-06\n",
            "(0.4119319021701813, 0.9375)\n",
            "5.713384143746225e-06\n",
            "(0.41235513967694715, 0.9375)\n",
            "5.635898651235038e-06\n",
            "(0.41277897730469704, 0.9375)\n",
            "5.6874561778386125e-06\n",
            "(0.41318395361304283, 0.9375)\n",
            "5.503874672285747e-06\n",
            "(0.41361520532518625, 0.9375)\n",
            "5.508941558218794e-06\n",
            "(0.41403942182660103, 0.9375)\n",
            "5.532485465664649e-06\n",
            "(0.41445644199848175, 0.9375)\n",
            "5.36022871528985e-06\n",
            "(0.41488294303417206, 0.9375)\n",
            "5.35993094672449e-06\n",
            "(0.4152970723807812, 0.9375)\n",
            "5.319698175298981e-06\n",
            "(0.4157151971012354, 0.9375)\n",
            "5.3709581152361355e-06\n",
            "(0.416122242808342, 0.9375)\n",
            "5.222245363256661e-06\n",
            "(0.4165564969953266, 0.9375)\n",
            "5.162640991329681e-06\n",
            "(0.4169832617044449, 0.9375)\n",
            "5.069956478109816e-06\n",
            "(0.417393365787575, 0.9375)\n",
            "5.0112460485252084e-06\n",
            "(0.41779850410330255, 0.9375)\n",
            "5.156680799700553e-06\n",
            "(0.4181821644306183, 0.9375)\n",
            "5.0490947614889595e-06\n",
            "(0.4186028577387333, 0.9375)\n",
            "4.993662969354773e-06\n",
            "(0.4190162979066372, 0.9375)\n",
            "4.920349238091149e-06\n",
            "(0.41943416744470596, 0.9375)\n",
            "4.9713107728166506e-06\n",
            "(0.4198445603251457, 0.9375)\n",
            "4.786239514942281e-06\n",
            "(0.4202665649354458, 0.9375)\n",
            "4.893229561275802e-06\n",
            "(0.42066140891984105, 0.9375)\n",
            "4.728423300548457e-06\n",
            "(0.42107242641213816, 0.9375)\n",
            "4.824386451218743e-06\n",
            "(0.4214794486761093, 0.9375)\n",
            "4.678653931478039e-06\n",
            "(0.4218895882368088, 0.9375)\n",
            "4.649149650504114e-06\n",
            "(0.42228865809738636, 0.9375)\n",
            "4.6568983634642794e-06\n",
            "(0.4226876199245453, 0.9375)\n",
            "4.635440745914821e-06\n",
            "(0.42309321742504835, 0.9375)\n",
            "4.589247600961243e-06\n",
            "(0.42351233959198, 0.9375)\n",
            "4.521596747508738e-06\n",
            "(0.4239071123301983, 0.9375)\n",
            "4.516530589171453e-06\n",
            "(0.42431237176060677, 0.9375)\n",
            "4.439342683326686e-06\n",
            "(0.4247199138626456, 0.9375)\n",
            "4.395831365400227e-06\n",
            "(0.42512280493974686, 0.9375)\n",
            "4.4342761611915195e-06\n",
            "(0.42551617324352264, 0.9375)\n",
            "4.360068851383403e-06\n",
            "(0.42592214047908783, 0.9375)\n",
            "4.363645120974979e-06\n",
            "(0.4263107539154589, 0.9375)\n",
            "4.320432026361232e-06\n",
            "(0.4267147295176983, 0.9375)\n",
            "4.2688743633334525e-06\n",
            "(0.4271186925470829, 0.9375)\n",
            "4.184534145679209e-06\n",
            "(0.427516155410558, 0.9375)\n",
            "4.186322166788159e-06\n",
            "(0.4279129975475371, 0.9375)\n",
            "4.089763206138741e-06\n",
            "(0.42830370366573334, 0.9375)\n",
            "4.11271089433285e-06\n",
            "(0.42868050560355186, 0.9375)\n",
            "4.151453822487383e-06\n",
            "(0.429067961871624, 0.9375)\n",
            "4.110624695385923e-06\n",
            "(0.4294569008052349, 0.9375)\n",
            "4.05340447287017e-06\n",
            "(0.42984940856695175, 0.9375)\n",
            "3.9008169551379975e-06\n",
            "(0.43025999248493463, 0.9375)\n",
            "3.998866168331005e-06\n",
            "(0.4306374229490757, 0.9375)\n",
            "3.9783028569218e-06\n",
            "(0.43102568201720715, 0.9375)\n",
            "3.945818298234371e-06\n",
            "(0.4314166009426117, 0.9375)\n",
            "3.90767154385685e-06\n",
            "(0.4318058490753174, 0.9375)\n",
            "3.839126475213561e-06\n",
            "(0.432201880030334, 0.9375)\n",
            "3.870716909659677e-06\n",
            "(0.43258365616202354, 0.9375)\n",
            "3.7971054553054274e-06\n",
            "(0.4329655668698251, 0.9375)\n",
            "3.8221393879211975e-06\n",
            "(0.4333493635058403, 0.9375)\n",
            "3.7169375445955664e-06\n",
            "(0.4337485767900944, 0.9375)\n",
            "3.7291565604391508e-06\n",
            "(0.43413084372878075, 0.9375)\n",
            "3.6686583371192683e-06\n",
            "(0.4345165304839611, 0.9375)\n",
            "3.6990566968597705e-06\n",
            "(0.4348879834942636, 0.9375)\n",
            "3.663293909994536e-06\n",
            "(0.4352697178728704, 0.9375)\n",
            "3.622465010266751e-06\n",
            "(0.4356541559100151, 0.9375)\n",
            "3.616206549850176e-06\n",
            "(0.43603321536977546, 0.9375)\n",
            "3.574185348043102e-06\n",
            "(0.4364220164716244, 0.9375)\n",
            "3.5759734601015224e-06\n",
            "(0.436806570738554, 0.9375)\n",
            "3.569714908735477e-06\n",
            "(0.437200453132391, 0.9375)\n",
            "3.4576585221657297e-06\n",
            "(0.4375929981470108, 0.9375)\n",
            "3.44365153068793e-06\n",
            "(0.4379763202741742, 0.9375)\n",
            "3.4072926609951536e-06\n",
            "(0.438361675478518, 0.9375)\n",
            "3.395372004888486e-06\n",
            "(0.4387326060968917, 0.9375)\n",
            "3.3596092180232517e-06\n",
            "(0.4391136132180691, 0.9375)\n",
            "3.3447081477788743e-06\n",
            "(0.43949759379029274, 0.9375)\n",
            "3.3384498237865045e-06\n",
            "(0.4398706369102001, 0.9375)\n",
            "3.3256349070143187e-06\n",
            "(0.44023749232292175, 0.9375)\n",
            "3.238910494474112e-06\n",
            "(0.44062005379237235, 0.9375)\n",
            "3.1813920941203833e-06\n",
            "(0.4409932605922222, 0.9375)\n",
            "3.2162608022190397e-06\n",
            "(0.44135290817939676, 0.9375)\n",
            "3.221327278879471e-06\n",
            "(0.4417126849293709, 0.9375)\n",
            "3.174239873260376e-06\n",
            "(0.44208909198641777, 0.9375)\n",
            "3.1912271879264153e-06\n",
            "(0.4424475865671411, 0.9375)\n",
            "3.1119532195589272e-06\n",
            "(0.44282156601548195, 0.9375)\n",
            "3.111059095317614e-06\n",
            "(0.4431897923350334, 0.9375)\n",
            "3.0422158943110844e-06\n",
            "(0.4435536153614521, 0.9375)\n",
            "3.0487725780403706e-06\n",
            "(0.4439264200627804, 0.9375)\n",
            "3.100926369370427e-06\n",
            "(0.44428393617272377, 0.9375)\n",
            "3.049368433494237e-06\n",
            "(0.4446670785546303, 0.9375)\n",
            "2.983207514262176e-06\n",
            "(0.44503792747855186, 0.9375)\n",
            "3.024632542292238e-06\n",
            "(0.4454062022268772, 0.9375)\n",
            "2.9438685487548357e-06\n",
            "(0.4457883727445733, 0.9375)\n",
            "2.910490002250299e-06\n",
            "(0.4461633935570717, 0.9375)\n",
            "2.8952908905921504e-06\n",
            "(0.4465280994772911, 0.9375)\n",
            "2.8693629246845375e-06\n",
            "(0.44689315548021113, 0.9375)\n",
            "2.892608745241887e-06\n",
            "(0.44724804582074285, 0.9375)\n",
            "2.7945593956246738e-06\n",
            "(0.4476114436984062, 0.9375)\n",
            "2.8532698706840164e-06\n",
            "(0.44796910136938095, 0.9375)\n",
            "2.831514166246052e-06\n",
            "(0.4483259557746351, 0.9375)\n",
            "2.8040961751685246e-06\n",
            "(0.44868917763233185, 0.9375)\n",
            "2.7614788450591733e-06\n",
            "(0.4490573778748512, 0.9375)\n",
            "2.757306583589525e-06\n",
            "(0.4494145028293133, 0.9375)\n",
            "2.723928037084988e-06\n",
            "(0.44978780345991254, 0.9375)\n",
            "2.736743044806644e-06\n",
            "(0.4501500613987446, 0.9375)\n",
            "2.669389914444764e-06\n",
            "(0.45052559627220035, 0.9375)\n",
            "2.685483286768431e-06\n",
            "(0.45087726041674614, 0.9375)\n",
            "2.638395608300925e-06\n",
            "(0.4512416124343872, 0.9375)\n",
            "2.646442226250656e-06\n",
            "(0.45159659534692764, 0.9375)\n",
            "2.6208123927062845e-06\n",
            "(0.451968455221504, 0.9375)\n",
            "2.6234943561576072e-06\n",
            "(0.4523374028503895, 0.9375)\n",
            "2.5522673240629957e-06\n",
            "(0.4527057416853495, 0.9375)\n",
            "2.568360514487722e-06\n",
            "(0.45306566706858575, 0.9375)\n",
            "2.549585087763262e-06\n",
            "(0.45342139358399436, 0.9375)\n",
            "2.5519691916997543e-06\n",
            "(0.4537781972485391, 0.9375)\n",
            "2.482231911926647e-06\n",
            "(0.4541464606882073, 0.9375)\n",
            "2.476569625287084e-06\n",
            "(0.4545036322087981, 0.9375)\n",
            "2.4905767077143535e-06\n",
            "(0.4548458536155522, 0.9375)\n",
            "2.470907293172786e-06\n",
            "(0.4552020334813278, 0.9375)\n",
            "2.458688277329202e-06\n",
            "(0.45556948333978653, 0.9375)\n",
            "2.443489074721583e-06\n",
            "(0.45592909900005907, 0.9375)\n",
            "2.3820965907361823e-06\n",
            "(0.4562997333705425, 0.9375)\n",
            "2.395805631749681e-06\n",
            "(0.4566570967435837, 0.9375)\n",
            "2.3493139906349823e-06\n",
            "(0.45702096819877625, 0.9375)\n",
            "2.334114924451569e-06\n",
            "(0.4573749266564846, 0.9375)\n",
            "2.3382872768706873e-06\n",
            "(0.45773500949144363, 0.9375)\n",
            "2.3370950202661333e-06\n",
            "(0.4581027328968048, 0.9375)\n",
            "2.3263663933903444e-06\n",
            "(0.45846547465771437, 0.9375)\n",
            "2.2906036519998453e-06\n",
            "(0.4588209241628647, 0.9375)\n",
            "2.247986321890494e-06\n",
            "(0.4591774046421051, 0.9375)\n",
            "2.253648699479527e-06\n",
            "(0.4595221057534218, 0.9375)\n",
            "2.2298069325188407e-06\n",
            "(0.459881778806448, 0.9375)\n",
            "2.222356442871387e-06\n",
            "(0.4602323230355978, 0.9375)\n",
            "2.192554211433162e-06\n",
            "(0.46059541404247284, 0.9375)\n",
            "2.1746727725258097e-06\n",
            "(0.4609505161643028, 0.9375)\n",
            "2.1767589259980014e-06\n",
            "(0.4612993970513344, 0.9375)\n",
            "2.149042848031968e-06\n",
            "(0.4616534262895584, 0.9375)\n",
            "2.1579836356977467e-06\n",
            "(0.4619920919649303, 0.9375)\n",
            "2.1222208488325123e-06\n",
            "(0.4623531164306769, 0.9375)\n",
            "2.111790035996819e-06\n",
            "(0.46270873863250017, 0.9375)\n",
            "2.086458152916748e-06\n",
            "(0.46305766326895537, 0.9375)\n",
            "2.0760273628184223e-06\n",
            "(0.4634063101548236, 0.9375)\n",
            "2.0575498183461606e-06\n",
            "(0.4637453928589821, 0.9375)\n",
            "2.0536756892397532e-06\n",
            "(0.46408357471227646, 0.9375)\n",
            "1.978573959604546e-06\n",
            "(0.46443115919828415, 0.9375)\n",
            "1.9714214658961284e-06\n",
            "(0.4647740349173546, 0.9375)\n",
            "2.0229793790349505e-06\n",
            "(0.46509787438162675, 0.9375)\n",
            "2.0390725467223093e-06\n",
            "(0.4654338282998651, 0.9375)\n",
            "1.9919849819416412e-06\n",
            "(0.46578763984143734, 0.9375)\n",
            "1.990196938095323e-06\n",
            "(0.4661335125565529, 0.9375)\n",
            "1.983938477678748e-06\n",
            "(0.46648497026762925, 0.9375)\n",
            "1.944301402545534e-06\n",
            "(0.46683244779706, 0.9375)\n",
            "1.9037703395952121e-06\n",
            "(0.46717362850904465, 0.9375)\n",
            "1.9171814074070426e-06\n",
            "(0.4675026759505272, 0.9375)\n",
            "1.917479471558181e-06\n",
            "(0.46784716844558716, 0.9375)\n",
            "1.8849948901333847e-06\n",
            "(0.46820363709957746, 0.9375)\n",
            "1.9097307358606485e-06\n",
            "(0.46854713559150696, 0.9375)\n",
            "1.9028764427275745e-06\n",
            "(0.4688931554555893, 0.9375)\n",
            "1.8554908137957683e-06\n",
            "(0.46924127638339996, 0.9375)\n",
            "1.8569809526525204e-06\n",
            "(0.46958310902118683, 0.9375)\n",
            "1.8444639181325328e-06\n",
            "(0.4699152419343591, 0.9375)\n",
            "1.8024427845375613e-06\n",
            "(0.47025576047599316, 0.9375)\n",
            "1.7991645790971234e-06\n",
            "(0.47058993577957153, 0.9375)\n",
            "1.8000586806010687e-06\n",
            "(0.47092172503471375, 0.9375)\n",
            "1.7896278677653753e-06\n",
            "(0.47126345708875306, 0.9375)\n",
            "1.7786009948395077e-06\n",
            "(0.47160670239827596, 0.9375)\n",
            "1.7994626205108943e-06\n",
            "(0.47193259189953096, 0.9375)\n",
            "1.770256380950741e-06\n",
            "(0.4722778758059576, 0.9375)\n",
            "1.766978130035568e-06\n",
            "(0.4726192504167557, 0.9375)\n",
            "1.7496928876425955e-06\n",
            "(0.47296232343796873, 0.9375)\n",
            "1.711843924567802e-06\n",
            "(0.4732989352196455, 0.9375)\n",
            "1.7127379805970122e-06\n",
            "(0.4736317992210388, 0.9375)\n",
            "1.6894921827770304e-06\n",
            "(0.47397515922784805, 0.9375)\n",
            "1.6754851230871282e-06\n",
            "(0.47430823370814323, 0.9375)\n",
            "1.6647562915750313e-06\n",
            "(0.47464701905846596, 0.9375)\n",
            "1.6495571571795153e-06\n",
            "(0.474986775952857, 0.9375)\n",
            "1.677273280620284e-06\n",
            "(0.4753173179924488, 0.9375)\n",
            "1.6421066220573266e-06\n",
            "(0.4756491659209132, 0.9375)\n",
            "1.6489610970893408e-06\n",
            "(0.4759732770908158, 0.9375)\n",
            "1.6468750345666194e-06\n",
            "(0.47630967292934656, 0.9375)\n",
            "1.6131983102241066e-06\n",
            "(0.4766458014200907, 0.9375)\n",
            "1.5962110410328024e-06\n",
            "(0.4769843965768814, 0.9375)\n",
            "1.6015753999454318e-06\n",
            "(0.47731367591768503, 0.9375)\n",
            "1.5819059399291292e-06\n",
            "(0.4776579551398754, 0.9375)\n",
            "1.5878664271440358e-06\n",
            "(0.4779953658432987, 0.9375)\n",
            "1.5640245692338794e-06\n",
            "(0.4783270014449954, 0.9375)\n",
            "1.5443550864802091e-06\n",
            "(0.4786525210365653, 0.9375)\n",
            "1.5541898164883604e-06\n",
            "(0.4789767302572727, 0.9375)\n",
            "1.5398847153846872e-06\n",
            "(0.4793016016483307, 0.9375)\n",
            "1.5261757425832912e-06\n",
            "(0.47961676120758057, 0.9375)\n",
            "1.5029298992885741e-06\n",
            "(0.4799501094967127, 0.9375)\n",
            "1.5082942127264686e-06\n",
            "(0.4802630511621828, 0.9375)\n",
            "1.4618027307733429e-06\n",
            "(0.4805929660797119, 0.9375)\n",
            "1.4594184676752775e-06\n",
            "(0.4809035031012172, 0.9375)\n",
            "1.4725315622854395e-06\n",
            "(0.48120771534740925, 0.9375)\n",
            "1.4471995427811636e-06\n",
            "(0.48152653872966766, 0.9375)\n",
            "1.4549481875292258e-06\n",
            "(0.4818384610116482, 0.9375)\n",
            "1.442729194423009e-06\n",
            "(0.48215214163064957, 0.9375)\n",
            "1.4621007494497461e-06\n",
            "(0.4824600927531719, 0.9375)\n",
            "1.4519679780278239e-06\n",
            "(0.48278529942035675, 0.9375)\n",
            "1.451073899261246e-06\n",
            "(0.4831010140478611, 0.9375)\n",
            "1.4322984497994185e-06\n",
            "(0.4834236800670624, 0.9375)\n",
            "1.4272320640884573e-06\n",
            "(0.48373760655522346, 0.9375)\n",
            "1.4051784319235593e-06\n",
            "(0.4840657413005829, 0.9375)\n",
            "1.384316783514805e-06\n",
            "(0.48438093066215515, 0.9375)\n",
            "1.3980258245283038e-06\n",
            "(0.4847048111134882, 0.9375)\n",
            "1.3783563417746336e-06\n",
            "(0.48503419011831284, 0.9375)\n",
            "1.357494716103247e-06\n",
            "(0.48536377359414473, 0.9375)\n",
            "1.3589847867478965e-06\n",
            "(0.4856809005141258, 0.9375)\n",
            "1.364051308883063e-06\n",
            "(0.485998310148716, 0.9375)\n",
            "1.3697136637347286e-06\n",
            "(0.4863200532436167, 0.9375)\n",
            "1.3488520380633418e-06\n",
            "(0.48663645707165415, 0.9375)\n",
            "1.3515342743630753e-06\n",
            "(0.4869486466050148, 0.9375)\n",
            "1.3428916417979054e-06\n",
            "(0.48726842552423477, 0.9375)\n",
            "1.31457948100433e-06\n",
            "(0.4875766783952713, 0.9375)\n",
            "1.3285865406942322e-06\n",
            "(0.487877526844386, 0.9375)\n",
            "1.3089170352031942e-06\n",
            "(0.48817603662610054, 0.9375)\n",
            "1.3023605561102158e-06\n",
            "(0.48847493063658476, 0.9375)\n",
            "1.295506058340834e-06\n",
            "(0.4887970983982086, 0.9375)\n",
            "1.278518720937427e-06\n",
            "(0.4891173447249457, 0.9375)\n",
            "1.2746444099320798e-06\n",
            "(0.48943363688886166, 0.9375)\n",
            "1.2785186982000596e-06\n",
            "(0.4897496849298477, 0.9375)\n",
            "1.2618294704225264e-06\n",
            "(0.4900655299425125, 0.9375)\n",
            "1.2680878853643662e-06\n",
            "(0.490375354886055, 0.9375)\n",
            "1.2516966762632365e-06\n",
            "(0.4906951002776623, 0.9375)\n",
            "1.2645115930354222e-06\n",
            "(0.4909970909357071, 0.9375)\n",
            "1.2534848337963921e-06\n",
            "(0.49130070954561234, 0.9375)\n",
            "1.243054020960699e-06\n",
            "(0.49162370337239736, 0.9375)\n",
            "1.2537828069980605e-06\n",
            "(0.49191732704639435, 0.9375)\n",
            "1.2314311106820241e-06\n",
            "(0.4922286570072174, 0.9375)\n",
            "1.219510181726946e-06\n",
            "(0.49253518879413605, 0.9375)\n",
            "1.1935822385567008e-06\n",
            "(0.4928532913327217, 0.9375)\n",
            "1.1906020290552987e-06\n",
            "(0.49315251410007477, 0.9375)\n",
            "1.1810652495114483e-06\n",
            "(0.49346237629652023, 0.9375)\n",
            "1.190601960843196e-06\n",
            "(0.49376489967107773, 0.9375)\n",
            "1.1607997066676034e-06\n",
            "(0.4940769411623478, 0.9375)\n",
            "1.175700867861451e-06\n",
            "(0.49437229335308075, 0.9375)\n",
            "1.16437597625918e-06\n",
            "(0.4946759045124054, 0.9375)\n",
            "1.175998863800487e-06\n",
            "(0.4949747668579221, 0.9375)\n",
            "1.1748067208827705e-06\n",
            "(0.49527514167129993, 0.9375)\n",
            "1.1733166729754884e-06\n",
            "(0.49557260423898697, 0.9375)\n",
            "1.1697403920152284e-06\n",
            "(0.4958784282207489, 0.9375)\n",
            "1.1616937626968138e-06\n",
            "(0.49619922786951065, 0.9375)\n",
            "1.153945186160854e-06\n",
            "(0.49650804698467255, 0.9375)\n",
            "1.1500708751555067e-06\n",
            "(0.49681912269443274, 0.9375)\n",
            "1.1485808272482246e-06\n",
            "(0.49713004380464554, 0.9375)\n",
            "1.1283151934549096e-06\n",
            "(0.4974454194307327, 0.9375)\n",
            "1.1056654557251021e-06\n",
            "(0.49775892494415075, 0.9375)\n",
            "1.1056654784624698e-06\n",
            "(0.49805986136198044, 0.9375)\n",
            "1.1071556400565896e-06\n",
            "(0.49836183339357376, 0.9375)\n",
            "1.0931485121545848e-06\n",
            "(0.49867384845856577, 0.9375)\n",
            "1.0964267858071253e-06\n",
            "(0.4989806952062281, 0.9375)\n",
            "1.088678186533798e-06\n",
            "(0.4992901459336281, 0.9375)\n",
            "1.084803852791083e-06\n",
            "(0.4995925948023796, 0.9375)\n",
            "1.0603660143715387e-06\n",
            "(0.4998958110809326, 0.9375)\n",
            "1.061558066339785e-06\n",
            "(0.5001932512968779, 0.9375)\n",
            "1.0657304528649546e-06\n",
            "(0.5004912856966257, 0.9375)\n",
            "1.0740751122284564e-06\n",
            "(0.5007821591570973, 0.9375)\n",
            "1.0642403140082025e-06\n",
            "(0.5010697971174523, 0.9375)\n",
            "1.0529154451432986e-06\n",
            "(0.5013736709952354, 0.9375)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}